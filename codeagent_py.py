# -*- coding: utf-8 -*-
"""CodeAgent.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J5vuW6kKpxuEgQqStUxxeWtGp1_WRrvQ
"""

# ai_assistant_gradio.py
from google import genai
import gradio as gr
import traceback

# ---------- CONFIG ----------
# Replace with your API key or set as env and pass None
CLIENT_API_KEY = "AIzaSyD4IcFq0ctSfJcocvc_5E5IDN6OEq9aeKg"  # <-- replace or set to None to rely on env var

# Initialize client (safe to re-init; if API key is None, it will rely on environment)
client = genai.Client(api_key=CLIENT_API_KEY)

MODEL_NAME = "gemini-2.0-flash"  # change if you want another model


# ---------- small helper to safely extract text from model response ----------
def _resp_text(resp):
    # The google-genai library response shape might vary; try common fields, otherwise fallback to str()
    try:
        if hasattr(resp, "text") and resp.text:
            return resp.text
        # older/newer shapes may have 'output' or 'outputs'
        data = resp
        # some SDKs return a dict-like object accessible via .to_dict()
        if hasattr(resp, "to_dict"):
            data = resp.to_dict()
        if isinstance(data, dict):
            # try some common nested paths
            for key in ("text", "output", "outputs", "content"):
                if key in data and data[key]:
                    return str(data[key])
            # dig deeper if possible
            if "candidates" in data and data["candidates"]:
                return str(data["candidates"][0].get("content", data["candidates"][0]))
        return str(resp)
    except Exception:
        return str(resp)


# ---------- wrapper for generating content ----------
def generate_with_model(contents: str, model=MODEL_NAME):
    try:
        resp = client.models.generate_content(model=model, contents=contents)
        return _resp_text(resp)
    except Exception as e:
        return f"Error calling model: {e}\n\n{traceback.format_exc()}"


# ---------- agent functions (same prompts as before) ----------
def intake_agent(code="", prompt=""):
    intake_prompt = f"""
You are an Intake Agent for a coding assistant system. Your task is to carefully read the user’s input, which may contain:
- A description of what they want the code to do: {prompt}
- Existing code that needs fixing:
{code}

Your outputs must include:
1. A clear summary of the task.
2. Identification of the programming language.
3. The user's requirements and constraints.
4. Whether the task is: [CREATE NEW CODE] or [FIX EXISTING CODE].

Do NOT attempt to fix or write code yet. Only analyze and summarize.
"""
    return generate_with_model(intake_prompt)


def code_understanding_agent(code, task_summary=""):
    prompt_text = f"""
You are a Code Understanding Agent. You receive:
- Existing code:
{code}
- User instructions:
{task_summary}

Your tasks:
1. Analyze the code line by line.
2. Identify syntax errors, logical errors, security issues, and potential optimizations.
3. List all findings clearly.
4. Suggest improvements but do NOT rewrite the code yet.

Output your findings in a structured, numbered format.
"""
    return generate_with_model(prompt_text)


def code_generation_agent(prompt, requirements=""):
    prompt_text = f"""
You are a Code Generation Agent. You will:
- Receive a user prompt describing the desired functionality: {prompt}
- Optionally receive analysis from the Code Understanding Agent: {requirements}

Your tasks:
1. Write clean, readable, and fully functional code that matches the user’s requirements.
2. Ensure the code is free of syntax errors and common bugs.
3. Include comments to explain complex sections.
4. Follow best practices for the given programming language.
5. Include minimal necessary dependencies or libraries.

Output only the code and comments.
"""
    return generate_with_model(prompt_text)


def code_fixing_agent(code, analysis="", requirements=""):
    prompt_text = f"""
You are a Code Fixing Agent. You receive:
- Existing code:
{code}
- Analysis from the Code Understanding Agent:
{analysis}
- User instructions:
{requirements}

Your tasks:
1. Correct all bugs, syntax errors, and logical mistakes.
2. Optimize and improve code readability without changing intended functionality.
3. Ensure it fully meets the user’s prompt or requirements.
4. Include comments explaining major fixes.
5. Output only the corrected code and comments.
"""
    return generate_with_model(prompt_text)


def code_validator_agent(code, requirements=""):
    prompt_text = f"""
You are a Code Validator Agent. You receive:
- Generated or fixed code:
{code}
- User instructions:
{requirements}

Your tasks:
1. Generate test cases or example runs to verify correctness.
2. Check if the code meets all requirements.
3. Report any remaining issues or confirm code is bug-free.
4. Suggest minor fixes if needed.
"""
    return generate_with_model(prompt_text)


def determine_task_type(ai_response):
    prompt = f"""
Based on the following AI analysis of user input (prompt + optional code):

{ai_response}

Determine the task type the user wants. Is it to create new code or fix existing code?

Answer only with one word: CREATE or FIX.
"""
    resp = generate_with_model(prompt)
    # try to normalize
    t = resp.strip().upper().split()[0] if resp else ""
    if t not in ["CREATE", "FIX"]:
        # fallback: if the user provided code consider it FIX otherwise CREATE
        # but don't assume silently; return UNKNOWN so UI can decide
        return "UNKNOWN", resp
    return t, resp


# ---------- orchestration function used by the Gradio UI ----------
def run_pipeline(user_prompt, user_code, force_task_type):
    # force_task_type: "AUTO", "CREATE", "FIX"
    outputs = {
        "intake": "",
        "task_type": "",
        "analysis": "",
        "generated_or_fixed": "",
        "validation": "",
        "errors": ""
    }
    try:
        # Intake
        intake = intake_agent(code=user_code or "", prompt=user_prompt or "")
        outputs["intake"] = intake

        # Determine task (unless user forced it)
        if force_task_type in ("CREATE", "FIX"):
            task_type = force_task_type
            task_detection_text = f"User forced task type: {force_task_type}"
        else:
            det, raw = determine_task_type(intake)
            task_type = det if det != "UNKNOWN" else ("FIX" if user_code.strip() else "CREATE")
            task_detection_text = raw

        outputs["task_type"] = f"{task_type}\n\n(DETECTOR RAW OUTPUT)\n{task_detection_text}"

        # Branch
        if task_type == "FIX":
            analysis = code_understanding_agent(user_code, intake)
            outputs["analysis"] = analysis

            fixed = code_fixing_agent(user_code, analysis, intake)
            outputs["generated_or_fixed"] = fixed

            validation = code_validator_agent(fixed, intake)
            outputs["validation"] = validation

        else:  # CREATE
            generated = code_generation_agent(user_prompt, intake)
            outputs["generated_or_fixed"] = generated

            validation = code_validator_agent(generated, intake)
            outputs["validation"] = validation

    except Exception as e:
        outputs["errors"] = f"Unexpected error: {e}\n\n{traceback.format_exc()}"

    return outputs["intake"], outputs["task_type"], outputs["analysis"], outputs["generated_or_fixed"], outputs["validation"], outputs["errors"]


# ---------- Build Gradio Interface ----------
with gr.Blocks(title="Casual Code Assistant", theme=gr.themes.Default()) as demo:
    gr.Markdown("## Casual Code Assistant — Gradio UI\nPaste your prompt and optional code, then press **Run**. This UI runs the Intake → Analysis → (Fix/Create) → Validation pipeline.")

    with gr.Row():
        with gr.Column(scale=2):
            user_prompt = gr.Textbox(lines=4, label="User prompt / desired functionality", placeholder="e.g. Build a simple Flask app that stores notes...")
            user_code = gr.Textbox(lines=12, label="Existing code (optional)", placeholder="Paste code here, or leave empty for CREATE tasks")
            task_choice = gr.Radio(choices=["AUTO", "CREATE", "FIX"], label="Task mode (AUTO = detect from input)", value="AUTO")
            run_btn = gr.Button("Run")
            clear_btn = gr.Button("Clear")
        with gr.Column(scale=1):
            gr.Markdown("**Pipeline outputs**")
            intake_out = gr.Textbox(lines=8, label="📝 Intake Agent", interactive=False)
            task_out = gr.Textbox(lines=3, label="🚦 Task Type Detection", interactive=False)
            analysis_out = gr.Textbox(lines=10, label="🔍 Code Understanding Analysis", interactive=False)
            gf_out = gr.Textbox(lines=16, label="🛠 Generated / Fixed Code", interactive=False)
            validate_out = gr.Textbox(lines=10, label="✅ Validation", interactive=False)
            errors_out = gr.Textbox(lines=6, label="❗ Errors / Traces", interactive=False)

    # wire up button
    run_btn.click(fn=run_pipeline, inputs=[user_prompt, user_code, task_choice],
                  outputs=[intake_out, task_out, analysis_out, gf_out, validate_out, errors_out])

    def _clear_all():
        return "", "", "", "", "", ""

    clear_btn.click(fn=_clear_all, outputs=[intake_out, task_out, analysis_out, gf_out, validate_out, errors_out])

    gr.Markdown("Tip: If detection isn't behaving how you want, set Task mode to CREATE or FIX to force behavior.")

# Launch
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", share=False)